{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\glede\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Iterable\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculations for stats and plots are based on: https://github.com/stasmix/popsynth/blob/master/pop-synth-vae.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_DATGAN(name):\n",
    "    if 'TGAN' in name or 'CTGAN' in name:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def compute_stats(freq_list_orig, freq_list_synth):\n",
    "    \"\"\"\n",
    "    Different statistics computed on the frequency list\n",
    "    \n",
    "    \"\"\"\n",
    "    freq_list_orig, freq_list_synth = np.array(freq_list_orig), np.array(freq_list_synth)\n",
    "    corr_mat = np.corrcoef(freq_list_orig, freq_list_synth)\n",
    "    corr = corr_mat[0, 1]\n",
    "    if np.isnan(corr): corr = 0.0\n",
    "    # MAE\n",
    "    mae = np.absolute(freq_list_orig - freq_list_synth).mean()\n",
    "    # RMSE\n",
    "    rmse = np.linalg.norm(freq_list_orig - freq_list_synth) / np.sqrt(len(freq_list_orig))\n",
    "    # SRMSE\n",
    "    freq_list_orig_avg = freq_list_orig.mean()\n",
    "    srmse = rmse / freq_list_orig_avg\n",
    "    # r-square\n",
    "    u = np.sum((freq_list_synth - freq_list_orig)**2)\n",
    "    v = np.sum((freq_list_orig - freq_list_orig_avg)**2)\n",
    "    r2 = 1.0 - u / v\n",
    "    stat = {'mae': mae, 'rmse': rmse, 'r2': r2, 'srmse': srmse, 'corr': corr}\n",
    "    \n",
    "    return stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'LPMC'\n",
    "\n",
    "input_folder = '../synth_data/{}/'.format(dataset)\n",
    "\n",
    "files_ = {}\n",
    "models = []\n",
    "\n",
    "for f in listdir(input_folder):\n",
    "    if isfile(join(input_folder, f)):\n",
    "        m = f.split('.')[0]\n",
    "        models.append(m)\n",
    "        files_[m] = join(input_folder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('../data/' + dataset + '/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is 'Chicago':\n",
    "    continuous_cols = ['distance', 'age', 'departure_time']\n",
    "elif dataset is 'LPMC':\n",
    "    continuous_cols = ['start_time_linear', 'age', 'distance', 'dur_walking', 'dur_cycling', 'dur_pt_access', 'dur_pt_rail', 'dur_pt_bus', 'dur_pt_int', 'dur_driving', 'cost_transit', 'cost_driving_fuel', 'driving_traffic_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_cont = {}\n",
    "\n",
    "for c in continuous_cols:\n",
    "    #bins_cont[c] = pd.qcut(df_orig[c], q=10, retbins=True)[1]\n",
    "    bins_cont[c] = pd.cut(df_orig[c], bins=10, retbins=True)[1]\n",
    "    bins_cont[c][0] = -np.inf\n",
    "    bins_cont[c][-1] = np.inf\n",
    "    df_orig[c] = pd.cut(df_orig[c], bins=bins_cont[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>faretype</th>\n",
       "      <th>bus_scale</th>\n",
       "      <th>survey_year</th>\n",
       "      <th>travel_year</th>\n",
       "      <th>travel_month</th>\n",
       "      <th>travel_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>dur_pt_access</th>\n",
       "      <th>dur_pt_rail</th>\n",
       "      <th>dur_pt_bus</th>\n",
       "      <th>dur_pt_int</th>\n",
       "      <th>pt_n_interchanges</th>\n",
       "      <th>dur_driving</th>\n",
       "      <th>cost_transit</th>\n",
       "      <th>cost_driving_fuel</th>\n",
       "      <th>cost_driving_con_charge</th>\n",
       "      <th>driving_traffic_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>child</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.106, 0.212]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(-inf, 0.215]</td>\n",
       "      <td>(-inf, 0.0567]</td>\n",
       "      <td>0</td>\n",
       "      <td>(-inf, 0.183]</td>\n",
       "      <td>(-inf, 1.17]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.104, 0.208]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.212, 0.318]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(-inf, 0.215]</td>\n",
       "      <td>(-inf, 0.0567]</td>\n",
       "      <td>0</td>\n",
       "      <td>(-inf, 0.183]</td>\n",
       "      <td>(-inf, 1.17]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(-inf, 0.104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Petrol_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.212, 0.318]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(0.859, 1.074]</td>\n",
       "      <td>(0.0567, 0.113]</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.362, 0.54]</td>\n",
       "      <td>(2.34, 3.51]</td>\n",
       "      <td>(1.027, 2.034]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.313, 0.417]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBW</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>full</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.106, 0.212]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(-inf, 0.215]</td>\n",
       "      <td>(0.0567, 0.113]</td>\n",
       "      <td>1</td>\n",
       "      <td>(-inf, 0.183]</td>\n",
       "      <td>(2.34, 3.51]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(-inf, 0.104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt</td>\n",
       "      <td>HBO</td>\n",
       "      <td>Average_Car</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.106, 0.212]</td>\n",
       "      <td>(-inf, 0.137]</td>\n",
       "      <td>(0.215, 0.429]</td>\n",
       "      <td>(-inf, 0.0567]</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.183, 0.362]</td>\n",
       "      <td>(-inf, 1.17]</td>\n",
       "      <td>(-inf, 1.027]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(-inf, 0.104]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  travel_mode purpose     fueltype faretype  bus_scale  survey_year  \\\n",
       "0       drive     HBO   Petrol_Car    child        0.0            1   \n",
       "1       drive     HBO   Petrol_Car     free        0.0            1   \n",
       "2       drive     HBO   Petrol_Car     full        1.0            1   \n",
       "3          pt     HBW  Average_Car     full        1.0            1   \n",
       "4          pt     HBO  Average_Car     free        0.0            1   \n",
       "\n",
       "   travel_year  travel_month  travel_date  day_of_week  ...   dur_pt_access  \\\n",
       "0         2012             4            1            7  ...  (0.106, 0.212]   \n",
       "1         2012             4            1            7  ...  (0.212, 0.318]   \n",
       "2         2012             4            1            7  ...  (0.212, 0.318]   \n",
       "3         2012             4            1            7  ...  (0.106, 0.212]   \n",
       "4         2012             4            1            7  ...  (0.106, 0.212]   \n",
       "\n",
       "     dur_pt_rail      dur_pt_bus       dur_pt_int  pt_n_interchanges  \\\n",
       "0  (-inf, 0.137]   (-inf, 0.215]   (-inf, 0.0567]                  0   \n",
       "1  (-inf, 0.137]   (-inf, 0.215]   (-inf, 0.0567]                  0   \n",
       "2  (-inf, 0.137]  (0.859, 1.074]  (0.0567, 0.113]                  1   \n",
       "3  (-inf, 0.137]   (-inf, 0.215]  (0.0567, 0.113]                  1   \n",
       "4  (-inf, 0.137]  (0.215, 0.429]   (-inf, 0.0567]                  0   \n",
       "\n",
       "      dur_driving  cost_transit cost_driving_fuel cost_driving_con_charge  \\\n",
       "0   (-inf, 0.183]  (-inf, 1.17]     (-inf, 1.027]                     0.0   \n",
       "1   (-inf, 0.183]  (-inf, 1.17]     (-inf, 1.027]                     0.0   \n",
       "2   (0.362, 0.54]  (2.34, 3.51]    (1.027, 2.034]                     0.0   \n",
       "3   (-inf, 0.183]  (2.34, 3.51]     (-inf, 1.027]                     0.0   \n",
       "4  (0.183, 0.362]  (-inf, 1.17]     (-inf, 1.027]                     0.0   \n",
       "\n",
       "  driving_traffic_percent  \n",
       "0          (0.104, 0.208]  \n",
       "1           (-inf, 0.104]  \n",
       "2          (0.313, 0.417]  \n",
       "3           (-inf, 0.104]  \n",
       "4           (-inf, 0.104]  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_str = ['mae', 'rmse', 'r2', 'srmse', 'corr']\n",
    "orig_str = 'random-original'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats per individual column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing stats for model \u001b[1mCTGAN\u001b[0m (1/29)\n",
      "Preparing stats for model \u001b[1mSGAN_OR_BO\u001b[0m (2/29)\n",
      "Preparing stats for model \u001b[1mSGAN_OR_NO\u001b[0m (3/29)\n",
      "Preparing stats for model \u001b[1mSGAN_OR_OD\u001b[0m (4/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WI_BO\u001b[0m (5/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WI_NO\u001b[0m (6/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WI_OD\u001b[0m (7/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WO_BO\u001b[0m (8/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WO_NO\u001b[0m (9/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WO_OD\u001b[0m (10/29)\n",
      "Preparing stats for model \u001b[1mTGAN\u001b[0m (11/29)\n",
      "Preparing stats for model \u001b[1mWGAN_OR_BO\u001b[0m (12/29)\n",
      "Preparing stats for model \u001b[1mWGAN_OR_NO\u001b[0m (13/29)\n",
      "Preparing stats for model \u001b[1mWGAN_OR_OD\u001b[0m (14/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WI_BO\u001b[0m (15/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WI_NO\u001b[0m (16/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WI_OD\u001b[0m (17/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WO_BO\u001b[0m (18/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WO_NO\u001b[0m (19/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WO_OD\u001b[0m (20/29)\n",
      "Preparing stats for model \u001b[1mWGGP_OR_BO\u001b[0m (21/29)\n",
      "Preparing stats for model \u001b[1mWGGP_OR_NO\u001b[0m (22/29)\n",
      "Preparing stats for model \u001b[1mWGGP_OR_OD\u001b[0m (23/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WI_BO\u001b[0m (24/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WI_NO\u001b[0m (25/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WI_OD\u001b[0m (26/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WO_BO\u001b[0m (27/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WO_NO\u001b[0m (28/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WO_OD\u001b[0m (29/29)\n"
     ]
    }
   ],
   "source": [
    "all_stats = {}\n",
    "\n",
    "# Go through each model\n",
    "for i, m in enumerate(models):\n",
    "    \n",
    "    print(\"Preparing stats for model \\033[1m{}\\033[0m ({}/{})\".format(m, i+1, len(models)))\n",
    "    \n",
    "    all_stats[m] = {}\n",
    "    \n",
    "    # Load all dataframes for current model\n",
    "    df = pd.read_csv(files_[m])\n",
    "       \n",
    "    # Discretize continuous columns\n",
    "    for c in continuous_cols:\n",
    "        df[c] = pd.cut(df[c], bins=bins_cont[c])\n",
    "\n",
    "    # Go through each columns\n",
    "    for c in df_orig.columns:\n",
    "\n",
    "        agg_vars = [c]\n",
    "\n",
    "        real = df_orig.copy()\n",
    "        real['count'] = 1\n",
    "        real = real.groupby(agg_vars, observed=True).count()\n",
    "        real /= len(df_orig)\n",
    "\n",
    "        synth = df.copy()\n",
    "        synth['count'] = 1\n",
    "        synth = synth.groupby(agg_vars, observed=True).count()\n",
    "        synth /= len(df)\n",
    "\n",
    "        real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "        real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "        sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "        \n",
    "        all_stats[m][c] = sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_orig = {}\n",
    "\n",
    "train = df_orig.sample(int(len(df_orig) * 0.5))\n",
    "train.index = range(len(train))\n",
    "test = df_orig[~df_orig.index.isin(train.index)]\n",
    "test.index = range(len(test))\n",
    "\n",
    "# Go through each columns\n",
    "for c in df_orig.columns:\n",
    "\n",
    "    agg_vars = [c]\n",
    "\n",
    "    real = train.copy()\n",
    "    real['count'] = 1\n",
    "    real = real.groupby(agg_vars, observed=True).count()\n",
    "    real /= len(df_orig)\n",
    "\n",
    "    synth = test.copy()\n",
    "    synth['count'] = 1\n",
    "    synth = synth.groupby(agg_vars, observed=True).count()\n",
    "    synth /= len(df)\n",
    "\n",
    "    real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "    real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "    sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "    \n",
    "    stats_orig[c] = sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats[orig_str] = stats_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for test in ['all', 'cont', 'cat']:\n",
    "    \n",
    "    res[test] = {}\n",
    "    \n",
    "    if test == 'all':\n",
    "        cols = df_orig.columns\n",
    "    elif test == 'cont':\n",
    "        cols = continuous_cols\n",
    "    elif test == 'cat':\n",
    "        cols = set(df_orig.columns) - set(continuous_cols)\n",
    "        \n",
    "    for s in stats_str:\n",
    "        res[test][s] = {}\n",
    "\n",
    "    for m in all_stats.keys():\n",
    "\n",
    "        for s in stats_str:\n",
    "            \n",
    "            tmp = []\n",
    "            for c in cols:\n",
    "                tmp.append(all_stats[m][c][s])\n",
    "            \n",
    "            res[test][s][m] = np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking on all columns based on SRMSE:\n",
      "   1. WGGP_WI_NO           - 8.25e-02\n",
      "   2. random-original      - 9.67e-02\n",
      "   3. WGGP_WI_OD           - 9.70e-02\n",
      "   4. WGAN_WI_NO           - 1.03e-01\n",
      "   5. WGGP_WO_NO           - 1.04e-01\n",
      "   6. WGGP_WI_BO           - 1.04e-01\n",
      "   7. WGGP_WO_OD           - 1.21e-01\n",
      "   8. WGGP_OR_OD           - 1.22e-01\n",
      "   9. WGGP_WO_BO           - 1.24e-01\n",
      "  10. WGGP_OR_BO           - 1.27e-01\n",
      "  11. WGGP_OR_NO           - 1.51e-01\n",
      "  12. TGAN                 - 1.52e-01\n",
      "  13. WGAN_WO_NO           - 1.72e-01\n",
      "  14. SGAN_WI_NO           - 1.81e-01\n",
      "  15. CTGAN                - 2.03e-01\n",
      "  16. WGAN_WI_OD           - 2.15e-01\n",
      "  17. WGAN_OR_NO           - 2.31e-01\n",
      "  18. WGAN_OR_OD           - 2.32e-01\n",
      "  19. WGAN_OR_BO           - 2.66e-01\n",
      "  20. SGAN_WI_OD           - 2.66e-01\n",
      "  21. WGAN_WO_OD           - 2.84e-01\n",
      "  22. WGAN_WI_BO           - 2.95e-01\n",
      "  23. SGAN_OR_NO           - 3.17e-01\n",
      "  24. SGAN_WI_BO           - 3.55e-01\n",
      "  25. SGAN_OR_OD           - 3.97e-01\n",
      "  26. WGAN_WO_BO           - 4.14e-01\n",
      "  27. SGAN_WO_NO           - 4.44e-01\n",
      "  28. SGAN_OR_BO           - 4.67e-01\n",
      "  29. SGAN_WO_OD           - 1.22e+00\n",
      "  30. SGAN_WO_BO           - 1.68e+00\n",
      "\n",
      "Ranking on continuous columns based on SRMSE:\n",
      "   1. random-original      - 2.56e-02\n",
      "   2. WGGP_WI_OD           - 1.40e-01\n",
      "   3. WGGP_OR_NO           - 1.41e-01\n",
      "   4. WGGP_WI_NO           - 1.41e-01\n",
      "   5. WGGP_OR_OD           - 1.42e-01\n",
      "   6. WGGP_WI_BO           - 1.52e-01\n",
      "   7. WGGP_OR_BO           - 1.54e-01\n",
      "   8. WGGP_WO_OD           - 1.77e-01\n",
      "   9. WGGP_WO_NO           - 1.79e-01\n",
      "  10. WGGP_WO_BO           - 1.83e-01\n",
      "  11. WGAN_WI_OD           - 1.95e-01\n",
      "  12. WGAN_WI_NO           - 1.96e-01\n",
      "  13. CTGAN                - 2.14e-01\n",
      "  14. TGAN                 - 2.55e-01\n",
      "  15. WGAN_OR_NO           - 3.04e-01\n",
      "  16. WGAN_OR_OD           - 3.15e-01\n",
      "  17. SGAN_WI_OD           - 3.30e-01\n",
      "  18. SGAN_WI_NO           - 3.33e-01\n",
      "  19. WGAN_WO_OD           - 3.44e-01\n",
      "  20. WGAN_WO_NO           - 3.45e-01\n",
      "  21. WGAN_WI_BO           - 3.68e-01\n",
      "  22. WGAN_OR_BO           - 3.84e-01\n",
      "  23. SGAN_OR_NO           - 4.88e-01\n",
      "  24. SGAN_OR_OD           - 4.90e-01\n",
      "  25. SGAN_WI_BO           - 5.25e-01\n",
      "  26. WGAN_WO_BO           - 6.23e-01\n",
      "  27. SGAN_OR_BO           - 6.38e-01\n",
      "  28. SGAN_WO_NO           - 9.07e-01\n",
      "  29. SGAN_WO_OD           - 9.10e-01\n",
      "  30. SGAN_WO_BO           - 1.89e+00\n",
      "\n",
      "Ranking on categorical columns based on SRMSE:\n",
      "   1. WGAN_WO_NO           - 2.22e-02\n",
      "   2. WGAN_WI_NO           - 2.30e-02\n",
      "   3. WGGP_WI_NO           - 3.13e-02\n",
      "   4. WGGP_WO_NO           - 3.82e-02\n",
      "   5. SGAN_WO_NO           - 4.34e-02\n",
      "   6. SGAN_WI_NO           - 4.97e-02\n",
      "   7. WGGP_WI_OD           - 5.96e-02\n",
      "   8. WGGP_WI_BO           - 6.21e-02\n",
      "   9. TGAN                 - 6.35e-02\n",
      "  10. WGGP_WO_OD           - 7.25e-02\n",
      "  11. WGGP_WO_BO           - 7.38e-02\n",
      "  12. WGGP_OR_BO           - 1.03e-01\n",
      "  13. WGGP_OR_OD           - 1.04e-01\n",
      "  14. random-original      - 1.58e-01\n",
      "  15. WGAN_OR_OD           - 1.60e-01\n",
      "  16. WGGP_OR_NO           - 1.60e-01\n",
      "  17. WGAN_OR_BO           - 1.63e-01\n",
      "  18. WGAN_OR_NO           - 1.67e-01\n",
      "  19. SGAN_OR_NO           - 1.69e-01\n",
      "  20. CTGAN                - 1.95e-01\n",
      "  21. SGAN_WI_BO           - 2.08e-01\n",
      "  22. SGAN_WI_OD           - 2.11e-01\n",
      "  23. WGAN_WI_BO           - 2.32e-01\n",
      "  24. WGAN_WO_OD           - 2.33e-01\n",
      "  25. WGAN_WI_OD           - 2.33e-01\n",
      "  26. WGAN_WO_BO           - 2.33e-01\n",
      "  27. SGAN_OR_OD           - 3.16e-01\n",
      "  28. SGAN_OR_BO           - 3.20e-01\n",
      "  29. SGAN_WO_OD           - 1.49e+00\n",
      "  30. SGAN_WO_BO           - 1.49e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test in ['all', 'cont', 'cat']:\n",
    "    \n",
    "    if test == 'all':\n",
    "        str_ = 'on all columns'\n",
    "    elif test == 'cont':\n",
    "        str_ = 'on continuous columns'\n",
    "    elif test == 'cat':\n",
    "        str_ = 'on categorical columns'\n",
    "        \n",
    "    for s in ['srmse']:#stats_str:\n",
    "        print('Ranking {} based on {}:'.format(str_, s.upper()))\n",
    "\n",
    "        if s in ['r2', 'corr']:\n",
    "            sorted_dct = {k: v for k, v in sorted(res[test][s].items(), key=lambda item: item[1])[::-1]}\n",
    "        else:\n",
    "            sorted_dct = {k: v for k, v in sorted(res[test][s].items(), key=lambda item: item[1])}\n",
    "\n",
    "        for i, item in enumerate(sorted_dct):\n",
    "            print('  {:>2}. {:<20} - {:.2e}'.format(i+1, item, sorted_dct[item]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats per couple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 378 combinations!\n"
     ]
    }
   ],
   "source": [
    "combs = []\n",
    "\n",
    "for k in combinations(df_orig.columns, 2):\n",
    "    combs.append(k[0] + '::' + k[1])\n",
    "    \n",
    "print('There are {} combinations!'.format(len(combs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing stats for model \u001b[1mCTGAN\u001b[0m (1/29)\n",
      "Preparing stats for model \u001b[1mSGAN_OR_BO\u001b[0m (2/29)\n",
      "Preparing stats for model \u001b[1mSGAN_OR_NO\u001b[0m (3/29)\n",
      "Preparing stats for model \u001b[1mSGAN_OR_OD\u001b[0m (4/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WI_BO\u001b[0m (5/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WI_NO\u001b[0m (6/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WI_OD\u001b[0m (7/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WO_BO\u001b[0m (8/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WO_NO\u001b[0m (9/29)\n",
      "Preparing stats for model \u001b[1mSGAN_WO_OD\u001b[0m (10/29)\n",
      "Preparing stats for model \u001b[1mTGAN\u001b[0m (11/29)\n",
      "Preparing stats for model \u001b[1mWGAN_OR_BO\u001b[0m (12/29)\n",
      "Preparing stats for model \u001b[1mWGAN_OR_NO\u001b[0m (13/29)\n",
      "Preparing stats for model \u001b[1mWGAN_OR_OD\u001b[0m (14/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WI_BO\u001b[0m (15/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WI_NO\u001b[0m (16/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WI_OD\u001b[0m (17/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WO_BO\u001b[0m (18/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WO_NO\u001b[0m (19/29)\n",
      "Preparing stats for model \u001b[1mWGAN_WO_OD\u001b[0m (20/29)\n",
      "Preparing stats for model \u001b[1mWGGP_OR_BO\u001b[0m (21/29)\n",
      "Preparing stats for model \u001b[1mWGGP_OR_NO\u001b[0m (22/29)\n",
      "Preparing stats for model \u001b[1mWGGP_OR_OD\u001b[0m (23/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WI_BO\u001b[0m (24/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WI_NO\u001b[0m (25/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WI_OD\u001b[0m (26/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WO_BO\u001b[0m (27/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WO_NO\u001b[0m (28/29)\n",
      "Preparing stats for model \u001b[1mWGGP_WO_OD\u001b[0m (29/29)\n"
     ]
    }
   ],
   "source": [
    "all_stats = {}\n",
    "\n",
    "# Go through each model\n",
    "for i, m in enumerate(models):\n",
    "    \n",
    "    print(\"Preparing stats for model \\033[1m{}\\033[0m ({}/{})\".format(m, i+1, len(models)))\n",
    "    \n",
    "    all_stats[m] = {}\n",
    "    \n",
    "    # Load all dataframes for current model\n",
    "    df = pd.read_csv(files_[m])\n",
    "       \n",
    "    # Discretize continuous columns\n",
    "    for c in continuous_cols:\n",
    "        df[c] = pd.cut(df[c], bins=bins_cont[c])\n",
    "\n",
    "    # Go through each columns\n",
    "    for c in combs:\n",
    "\n",
    "        agg_vars = c.split('::')\n",
    "\n",
    "        real = df_orig.copy()\n",
    "        real['count'] = 1\n",
    "        real = real.groupby(agg_vars, observed=True).count()\n",
    "        real /= len(df_orig)\n",
    "\n",
    "        synth = df.copy()\n",
    "        synth['count'] = 1\n",
    "        synth = synth.groupby(agg_vars, observed=True).count()\n",
    "        synth /= len(df)\n",
    "\n",
    "        real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "        real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "        sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "        \n",
    "        all_stats[m][c] = sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_orig = {}\n",
    "\n",
    "train = df_orig.sample(int(len(df_orig) * 0.5))\n",
    "train.index = range(len(train))\n",
    "test = df_orig[~df_orig.index.isin(train.index)]\n",
    "test.index = range(len(test))\n",
    "\n",
    "# Go through each columns\n",
    "for c in combs:\n",
    "\n",
    "    agg_vars = c.split('::')\n",
    "\n",
    "    real = train.copy()\n",
    "    real['count'] = 1\n",
    "    real = real.groupby(agg_vars, observed=True).count()\n",
    "    real /= len(df_orig)\n",
    "\n",
    "    synth = test.copy()\n",
    "    synth['count'] = 1\n",
    "    synth = synth.groupby(agg_vars, observed=True).count()\n",
    "    synth /= len(df)\n",
    "\n",
    "    real_and_sampled = pd.merge(real, synth, suffixes=['_real', '_sampled'], on=agg_vars, how='outer', indicator=True)\n",
    "    real_and_sampled = real_and_sampled[['count_real', 'count_sampled']].fillna(0)\n",
    "\n",
    "    sts = compute_stats(real_and_sampled['count_real'], real_and_sampled['count_sampled'])\n",
    "    \n",
    "    stats_orig[c] = sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats[orig_str] = stats_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for s in stats_str:\n",
    "    res[s] = {}\n",
    "                    \n",
    "for m in all_stats.keys():\n",
    "\n",
    "    for s in stats_str:\n",
    "\n",
    "        tmp = []\n",
    "        for c in combs:\n",
    "            tmp.append(all_stats[m][c][s])\n",
    "\n",
    "        res[s][m] = np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking on all coupled combinations based on MAE:\n",
      "   1. random-original      - 3.60e-03\n",
      "   2. WGGP_WI_NO           - 3.87e-03\n",
      "   3. WGGP_WI_OD           - 4.03e-03\n",
      "   4. WGGP_WI_BO           - 4.27e-03\n",
      "   5. WGGP_WO_NO           - 4.63e-03\n",
      "   6. TGAN                 - 5.09e-03\n",
      "   7. WGGP_WO_OD           - 5.11e-03\n",
      "   8. WGGP_OR_OD           - 5.15e-03\n",
      "   9. WGGP_WO_BO           - 5.24e-03\n",
      "  10. WGGP_OR_BO           - 5.33e-03\n",
      "  11. WGAN_WI_NO           - 5.78e-03\n",
      "  12. SGAN_WI_NO           - 6.72e-03\n",
      "  13. WGAN_WO_NO           - 7.13e-03\n",
      "  14. CTGAN                - 7.86e-03\n",
      "  15. WGGP_OR_NO           - 7.97e-03\n",
      "  16. WGAN_WI_OD           - 9.60e-03\n",
      "  17. WGAN_OR_OD           - 9.88e-03\n",
      "  18. WGAN_OR_BO           - 1.01e-02\n",
      "  19. WGAN_OR_NO           - 1.05e-02\n",
      "  20. SGAN_WI_OD           - 1.06e-02\n",
      "  21. WGAN_WI_BO           - 1.09e-02\n",
      "  22. SGAN_WI_BO           - 1.18e-02\n",
      "  23. WGAN_WO_OD           - 1.26e-02\n",
      "  24. SGAN_OR_NO           - 1.28e-02\n",
      "  25. WGAN_WO_BO           - 1.48e-02\n",
      "  26. SGAN_OR_OD           - 1.50e-02\n",
      "  27. SGAN_WO_NO           - 1.52e-02\n",
      "  28. SGAN_OR_BO           - 1.56e-02\n",
      "  29. SGAN_WO_OD           - 5.07e-02\n",
      "  30. SGAN_WO_BO           - 5.62e-02\n",
      "\n",
      "Ranking on all coupled combinations based on RMSE:\n",
      "   1. random-original      - 5.61e-03\n",
      "   2. WGGP_WI_NO           - 6.78e-03\n",
      "   3. WGGP_WI_OD           - 7.00e-03\n",
      "   4. WGGP_WI_BO           - 7.38e-03\n",
      "   5. WGGP_WO_NO           - 7.90e-03\n",
      "   6. WGGP_OR_OD           - 8.36e-03\n",
      "   7. WGGP_WO_OD           - 8.54e-03\n",
      "   8. WGGP_OR_BO           - 8.61e-03\n",
      "   9. WGGP_WO_BO           - 8.78e-03\n",
      "  10. TGAN                 - 8.93e-03\n",
      "  11. WGAN_WI_NO           - 9.94e-03\n",
      "  12. WGGP_OR_NO           - 1.22e-02\n",
      "  13. SGAN_WI_NO           - 1.23e-02\n",
      "  14. WGAN_WO_NO           - 1.29e-02\n",
      "  15. CTGAN                - 1.30e-02\n",
      "  16. WGAN_WI_OD           - 1.63e-02\n",
      "  17. WGAN_OR_NO           - 1.64e-02\n",
      "  18. WGAN_OR_OD           - 1.69e-02\n",
      "  19. WGAN_OR_BO           - 1.85e-02\n",
      "  20. SGAN_WI_OD           - 1.91e-02\n",
      "  21. WGAN_WI_BO           - 1.93e-02\n",
      "  22. SGAN_OR_NO           - 2.12e-02\n",
      "  23. WGAN_WO_OD           - 2.24e-02\n",
      "  24. SGAN_WI_BO           - 2.34e-02\n",
      "  25. SGAN_OR_OD           - 2.69e-02\n",
      "  26. SGAN_WO_NO           - 2.82e-02\n",
      "  27. WGAN_WO_BO           - 2.92e-02\n",
      "  28. SGAN_OR_BO           - 3.03e-02\n",
      "  29. SGAN_WO_OD           - 1.05e-01\n",
      "  30. SGAN_WO_BO           - 1.41e-01\n",
      "\n",
      "Ranking on all coupled combinations based on R2:\n",
      "   1. WGGP_WI_NO           - 9.43e-01\n",
      "   2. WGGP_WO_NO           - 9.17e-01\n",
      "   3. WGAN_WI_NO           - 9.15e-01\n",
      "   4. WGGP_OR_NO           - 9.00e-01\n",
      "   5. WGAN_OR_NO           - 8.61e-01\n",
      "   6. SGAN_WI_NO           - 8.61e-01\n",
      "   7. WGAN_WO_NO           - 8.59e-01\n",
      "   8. WGAN_OR_OD           - 8.32e-01\n",
      "   9. TGAN                 - 8.02e-01\n",
      "  10. WGGP_WI_OD           - 7.74e-01\n",
      "  11. WGGP_OR_OD           - 7.72e-01\n",
      "  12. WGGP_OR_BO           - 7.68e-01\n",
      "  13. WGAN_OR_BO           - 7.64e-01\n",
      "  14. WGGP_WO_OD           - 7.60e-01\n",
      "  15. WGGP_WI_BO           - 7.59e-01\n",
      "  16. WGGP_WO_BO           - 7.50e-01\n",
      "  17. SGAN_OR_NO           - 7.12e-01\n",
      "  18. WGAN_WO_OD           - 6.90e-01\n",
      "  19. SGAN_WI_OD           - 5.05e-01\n",
      "  20. SGAN_WI_BO           - 4.04e-01\n",
      "  21. WGAN_WI_OD           - 3.68e-01\n",
      "  22. WGAN_WO_BO           - 3.35e-01\n",
      "  23. SGAN_WO_NO           - 2.78e-01\n",
      "  24. CTGAN                - 2.68e-01\n",
      "  25. WGAN_WI_BO           - 2.30e-01\n",
      "  26. SGAN_OR_OD           - -2.05e-01\n",
      "  27. SGAN_OR_BO           - -3.64e-01\n",
      "  28. random-original      - -1.00e+00\n",
      "  29. SGAN_WO_OD           - -6.49e+01\n",
      "  30. SGAN_WO_BO           - -7.72e+01\n",
      "\n",
      "Ranking on all coupled combinations based on SRMSE:\n",
      "   1. WGGP_WI_NO           - 2.59e-01\n",
      "   2. random-original      - 2.68e-01\n",
      "   3. WGGP_WI_OD           - 3.05e-01\n",
      "   4. WGGP_WO_NO           - 3.06e-01\n",
      "   5. WGGP_WI_BO           - 3.16e-01\n",
      "   6. WGGP_OR_OD           - 3.21e-01\n",
      "   7. WGGP_OR_BO           - 3.26e-01\n",
      "   8. WGGP_WO_OD           - 3.46e-01\n",
      "   9. WGGP_WO_BO           - 3.56e-01\n",
      "  10. TGAN                 - 3.65e-01\n",
      "  11. WGAN_WI_NO           - 3.83e-01\n",
      "  12. WGGP_OR_NO           - 3.86e-01\n",
      "  13. SGAN_WI_NO           - 4.80e-01\n",
      "  14. CTGAN                - 4.82e-01\n",
      "  15. WGAN_WO_NO           - 4.91e-01\n",
      "  16. WGAN_OR_NO           - 5.43e-01\n",
      "  17. WGAN_OR_OD           - 5.57e-01\n",
      "  18. WGAN_WI_OD           - 5.75e-01\n",
      "  19. WGAN_OR_BO           - 6.24e-01\n",
      "  20. SGAN_WI_OD           - 6.37e-01\n",
      "  21. WGAN_WO_OD           - 6.93e-01\n",
      "  22. WGAN_WI_BO           - 7.05e-01\n",
      "  23. SGAN_OR_NO           - 7.40e-01\n",
      "  24. SGAN_WI_BO           - 8.32e-01\n",
      "  25. SGAN_OR_OD           - 9.45e-01\n",
      "  26. WGAN_WO_BO           - 1.01e+00\n",
      "  27. SGAN_OR_BO           - 1.10e+00\n",
      "  28. SGAN_WO_NO           - 1.13e+00\n",
      "  29. SGAN_WO_OD           - 3.35e+00\n",
      "  30. SGAN_WO_BO           - 5.10e+00\n",
      "\n",
      "Ranking on all coupled combinations based on CORR:\n",
      "   1. WGGP_WI_NO           - 9.75e-01\n",
      "   2. WGGP_WO_NO           - 9.67e-01\n",
      "   3. WGAN_OR_OD           - 9.61e-01\n",
      "   4. WGGP_WI_OD           - 9.61e-01\n",
      "   5. WGGP_OR_NO           - 9.60e-01\n",
      "   6. WGAN_WI_NO           - 9.60e-01\n",
      "   7. WGGP_WI_BO           - 9.58e-01\n",
      "   8. WGGP_WO_OD           - 9.56e-01\n",
      "   9. SGAN_WI_NO           - 9.55e-01\n",
      "  10. WGGP_WO_BO           - 9.53e-01\n",
      "  11. WGGP_OR_OD           - 9.52e-01\n",
      "  12. WGAN_OR_BO           - 9.52e-01\n",
      "  13. WGAN_WO_NO           - 9.52e-01\n",
      "  14. WGGP_OR_BO           - 9.50e-01\n",
      "  15. WGAN_OR_NO           - 9.49e-01\n",
      "  16. WGAN_WO_OD           - 9.44e-01\n",
      "  17. TGAN                 - 9.41e-01\n",
      "  18. WGAN_WI_OD           - 9.38e-01\n",
      "  19. SGAN_WI_OD           - 9.29e-01\n",
      "  20. random-original      - 9.27e-01\n",
      "  21. SGAN_OR_NO           - 9.21e-01\n",
      "  22. SGAN_WI_BO           - 9.18e-01\n",
      "  23. WGAN_WI_BO           - 9.18e-01\n",
      "  24. CTGAN                - 9.16e-01\n",
      "  25. WGAN_WO_BO           - 9.07e-01\n",
      "  26. SGAN_OR_OD           - 8.89e-01\n",
      "  27. SGAN_OR_BO           - 8.81e-01\n",
      "  28. SGAN_WO_NO           - 8.24e-01\n",
      "  29. SGAN_WO_OD           - 5.71e-01\n",
      "  30. SGAN_WO_BO           - 5.29e-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in ['srmse']:#stats_str:\n",
    "    print('Ranking on all coupled combinations based on {}:'.format(s.upper()))\n",
    "\n",
    "    if s in ['r2', 'corr']:\n",
    "        sorted_dct = {k: v for k, v in sorted(res[s].items(), key=lambda item: item[1])[::-1]}\n",
    "    else:\n",
    "        sorted_dct = {k: v for k, v in sorted(res[s].items(), key=lambda item: item[1])}\n",
    "\n",
    "    for i, item in enumerate(sorted_dct):\n",
    "        print('  {:>2}. {:<20} - {:.2e}'.format(i+1, item, sorted_dct[item]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
